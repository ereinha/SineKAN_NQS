{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIaCGVyi72xd"
      },
      "outputs": [],
      "source": [
        "import netket as nk\n",
        "from jax import numpy as jnp\n",
        "from jax.nn.initializers import truncated_normal, zeros\n",
        "from netket import experimental as nkx\n",
        "from netket.jax import dtype_real\n",
        "from netket.nn import log_cosh\n",
        "\n",
        "from ham import ColoredJ1J2, Hubbard, tVModel, J1J2OneD\n",
        "import sym_sinekan\n",
        "import mlp\n",
        "\n",
        "\n",
        "def get_ham():\n",
        "    L = args.L\n",
        "    L2 = args.L2\n",
        "\n",
        "    if args.boundary == \"peri\":\n",
        "        pbc = True\n",
        "    elif args.boundary == \"open\":\n",
        "        pbc = False\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown boundary: {args.boundary}\")\n",
        "\n",
        "    if args.ham.endswith(\"tri\"):\n",
        "        assert args.ham_dim == 2\n",
        "        graph = ColoredJ1J2((L, L2), pbc, back_diag=False)\n",
        "    elif args.ham.endswith(\"kag\"):\n",
        "        assert args.ham_dim == 2\n",
        "        # Nikita's kagome_sqrt18: extent = [3, 2]\n",
        "        graph = nk.graph.Lattice(\n",
        "            basis_vectors=[[1, 0], [-0.5, 0.75**0.5]],\n",
        "            extent=[L, L2],\n",
        "            pbc=pbc,\n",
        "            site_offsets=[[0.5, 0], [0.25, 0.75**0.5 / 2], [0.75, 0.75**0.5 / 2]],\n",
        "        )\n",
        "    elif args.ham == \"j1j2\":\n",
        "        assert args.ham_dim == 2\n",
        "        graph = ColoredJ1J2((L, L2), pbc)\n",
        "    else:\n",
        "        if args.ham_dim == 2:\n",
        "            extent = [L, L2]\n",
        "        else:\n",
        "            extent = [L] * args.ham_dim\n",
        "        graph = nk.graph.Grid(extent=extent, pbc=pbc)\n",
        "\n",
        "    if args.ham == \"hubb\":\n",
        "        assert not args.zero_mag\n",
        "        hilbert = nkx.hilbert.SpinOrbitalFermions(\n",
        "            n_orbitals=graph.n_nodes, s=1 / 2, n_fermions=(args.Nf,) * 2\n",
        "        )\n",
        "    elif args.ham == \"tv\":\n",
        "        assert not args.zero_mag\n",
        "        hilbert = nkx.hilbert.SpinOrbitalFermions(\n",
        "            n_orbitals=graph.n_nodes, n_fermions=args.Nf\n",
        "        )\n",
        "    else:\n",
        "        assert not args.Nf\n",
        "        if args.zero_mag:\n",
        "            hilbert = nk.hilbert.Spin(s=1 / 2, N=graph.n_nodes, total_sz=0)\n",
        "        else:\n",
        "            hilbert = nk.hilbert.Spin(s=1 / 2, N=graph.n_nodes)\n",
        "\n",
        "    J = 1\n",
        "    sign = args.sign == \"mars\"\n",
        "\n",
        "    if args.ham == \"ising\":\n",
        "        assert args.sign == \"none\"\n",
        "        assert not args.J2\n",
        "        assert not args.U\n",
        "        assert not args.V\n",
        "        H = nk.operator.IsingJax(hilbert=hilbert, graph=graph, J=-J, h=args.h)\n",
        "    elif args.ham.startswith(\"heis\"):\n",
        "        assert not args.J2\n",
        "        assert not args.U\n",
        "        assert not args.V\n",
        "        assert not args.h\n",
        "        if args.ham.endswith(\"tri\"):\n",
        "            H = nk.operator.Heisenberg(\n",
        "                hilbert=hilbert, graph=graph, J=[J, J], sign_rule=[sign, False]\n",
        "            )\n",
        "        else:\n",
        "            H = nk.operator.Heisenberg(\n",
        "                hilbert=hilbert, graph=graph, J=J, sign_rule=sign\n",
        "            )\n",
        "    elif args.ham == \"j1j2\":\n",
        "        assert not args.U\n",
        "        assert not args.V\n",
        "        assert not args.h\n",
        "        H = nk.operator.Heisenberg(\n",
        "            hilbert=hilbert, graph=graph, J=[J, args.J2], sign_rule=[sign, False],\n",
        "        )\n",
        "    elif args.ham == \"hubb\":\n",
        "        assert args.sign == \"none\"\n",
        "        assert not args.J2\n",
        "        assert not args.V\n",
        "        assert not args.h\n",
        "        H = Hubbard(hilbert=hilbert, graph=graph, U=args.U)\n",
        "    elif args.ham == \"tv\":\n",
        "        assert args.sign == \"none\"\n",
        "        assert not args.J2\n",
        "        assert not args.U\n",
        "        assert not args.h\n",
        "        H = tVModel(hilbert=hilbert, graph=graph, V=args.V)\n",
        "    elif args.ham == \"j1j2_1d\":\n",
        "        H, graph, hilbert = J1J2OneD(L, args.J2, pbc, use_marshall=args.sign==\"mars\",\n",
        "                                     total_sz=0 if args.zero_mag else None)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown ham: {args.ham}\")\n",
        "\n",
        "    return graph, hilbert, H\n",
        "\n",
        "\n",
        "def get_net(graph, hilbert):\n",
        "    N = hilbert.size\n",
        "    if args.net == \"jas\":\n",
        "        assert args.layers == 1\n",
        "        assert args.features == 1\n",
        "        return nk.models.Jastrow(\n",
        "            param_dtype=args.dtype, kernel_init=truncated_normal(stddev=1 / N)\n",
        "        )\n",
        "    elif args.net == \"rbm\":\n",
        "        assert args.layers == 1\n",
        "        alpha = args.features\n",
        "        if jnp.issubdtype(args.dtype, jnp.floating):\n",
        "            kernel_init = truncated_normal(stddev=1 / (alpha**0.5 * N))\n",
        "        else:\n",
        "            kernel_init = truncated_normal(stddev=1 / (alpha**0.25 * N**0.75))\n",
        "\n",
        "        return nk.models.RBM(\n",
        "            alpha=alpha,\n",
        "            param_dtype=args.dtype,\n",
        "            activation=log_cosh,\n",
        "            kernel_init=kernel_init,\n",
        "            hidden_bias_init=zeros,\n",
        "            visible_bias_init=zeros,\n",
        "        )\n",
        "    elif args.net == \"gcnn\":\n",
        "        return nk.models.GCNN(\n",
        "            symmetries=graph,\n",
        "            layers=args.layers,\n",
        "            features=args.features,\n",
        "            param_dtype=args.dtype,\n",
        "        )\n",
        "    elif args.net == \"rnn_lstm\":\n",
        "        return nkx.models.FastLSTMNet(\n",
        "            hilbert=hilbert,\n",
        "            layers=args.layers,\n",
        "            features=args.features,\n",
        "            graph=graph,\n",
        "            param_dtype=args.dtype,\n",
        "        )\n",
        "    elif args.net == \"mlp\":\n",
        "        return mlp.MLP(\n",
        "            layers_hidden=args.layers_hidden,\n",
        "        )\n",
        "    elif args.net == \"symmlp\":\n",
        "        return mlp.SymmetricMLP(\n",
        "            layers_hidden=args.layers_hidden,\n",
        "        )\n",
        "    elif args.net == \"sinekan\":\n",
        "        return sym_sinekan.SineKAN(\n",
        "            layers_hidden=args.layers_hidden,\n",
        "            grid_size=args.grid_size,\n",
        "        )\n",
        "    elif args.net == \"sym_sinekan\":\n",
        "        return sym_sinekan.SymmetricSineKAN1D(\n",
        "            layers_hidden=args.layers_hidden,\n",
        "            grid_size=args.grid_size,\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown net: {args.net}\")\n",
        "\n",
        "\n",
        "def get_sampler(graph, hilbert):\n",
        "    if args.ham in [\"hubb\", \"tv\"] or args.zero_mag:\n",
        "        if args.net.startswith(\"rnn\"):\n",
        "            raise NotImplementedError\n",
        "        elif args.net.endswith(\"sinekan\"):\n",
        "            return nk.sampler.MetropolisLocal(\n",
        "                hilbert, n_chains=args.batch_size, dtype=dtype_real(args.dtype)\n",
        "            )\n",
        "        else:\n",
        "            if args.ham == \"hubb\":\n",
        "                graph = nk.graph.disjoint_union(graph, graph)\n",
        "            return nk.sampler.MetropolisExchange(\n",
        "                hilbert,\n",
        "                graph=graph,\n",
        "                n_chains=args.batch_size,\n",
        "                dtype=dtype_real(args.dtype),\n",
        "            )\n",
        "    else:\n",
        "        if args.net.startswith(\"rnn\"):\n",
        "            return nk.sampler.ARDirectSampler(hilbert, dtype=dtype_real(args.dtype))\n",
        "        else:\n",
        "            return nk.sampler.MetropolisLocal(\n",
        "                hilbert, n_chains=args.batch_size, dtype=dtype_real(args.dtype)\n",
        "            )\n",
        "\n",
        "\n",
        "def get_vstate(sampler, model):\n",
        "    return nk.vqs.MCState(\n",
        "        sampler,\n",
        "        model,\n",
        "        n_samples=args.batch_size,\n",
        "        n_discard_per_chain=0,\n",
        "        chunk_size=args.chunk_size,\n",
        "        seed=args.seed,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RTLaJzd60rB",
        "outputId": "51cd3273-c024-4f0e-981f-87f5b5f72c5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Variational state built with 91905 parameters.\n",
            "Hamiltonian: LocalOperator(dim=100, #acting_on=200 locations, constant=0.0, dtype=float64)\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "import os\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import netket as nk\n",
        "import flax\n",
        "\n",
        "# --- Provided Functions (unchanged) --- #\n",
        "\n",
        "def parse_tuple(arg_str):\n",
        "    try:\n",
        "        return tuple(int(x.strip()) for x in arg_str.split(\",\"))\n",
        "    except ValueError:\n",
        "        raise argparse.ArgumentTypeError(\n",
        "            f\"Invalid tuple format: '{arg_str}'. Expected format: '64,64'.\"\n",
        "        )\n",
        "\n",
        "def get_parser():\n",
        "    parser = argparse.ArgumentParser(allow_abbrev=False)\n",
        "\n",
        "    group = parser.add_argument_group(\"physics parameters\")\n",
        "    group.add_argument(\n",
        "        \"--ham\",\n",
        "        type=str,\n",
        "        default=\"ising\",\n",
        "        choices=[\"ising\", \"heis\", \"heis_tri\", \"heis_kag\", \"j1j2\", \"hubb\", \"tv\", \"j1j2_1d\"],\n",
        "        help=\"Hamiltonian type\",\n",
        "    )\n",
        "    group.add_argument(\n",
        "        \"--boundary\",\n",
        "        type=str,\n",
        "        default=\"open\",\n",
        "        choices=[\"open\", \"peri\"],\n",
        "        help=\"boundary conditions\",\n",
        "    )\n",
        "    group.add_argument(\n",
        "        \"--sign\",\n",
        "        type=str,\n",
        "        default=\"none\",\n",
        "        choices=[\"none\", \"mars\"],\n",
        "        help=\"sign rule\",\n",
        "    )\n",
        "    group.add_argument(\n",
        "        \"--ham_dim\",\n",
        "        type=int,\n",
        "        default=1,\n",
        "        choices=[1, 2],\n",
        "        help=\"dimension of the lattice\",\n",
        "    )\n",
        "    group.add_argument(\n",
        "        \"--L\",\n",
        "        type=int,\n",
        "        default=4,\n",
        "        help=\"edge length of the lattice\",\n",
        "    )\n",
        "    group.add_argument(\n",
        "        \"--L2\",\n",
        "        type=int,\n",
        "        default=0,\n",
        "        help=\"another edge length of the lattice\",\n",
        "    )\n",
        "    group.add_argument(\n",
        "        \"--J2\",\n",
        "        type=float,\n",
        "        default=0,\n",
        "        help=\"2nd nearest neighbor interaction\",\n",
        "    )\n",
        "    group.add_argument(\n",
        "        \"--U\",\n",
        "        type=float,\n",
        "        default=0,\n",
        "        help=\"on-site interaction\",\n",
        "    )\n",
        "    group.add_argument(\n",
        "        \"--V\",\n",
        "        type=float,\n",
        "        default=0,\n",
        "        help=\"repulsive interaction\",\n",
        "    )\n",
        "    group.add_argument(\n",
        "        \"--h\",\n",
        "        type=float,\n",
        "        default=0,\n",
        "        help=\"external field\",\n",
        "    )\n",
        "    group.add_argument(\n",
        "        \"--zero_mag\",\n",
        "        action=\"store_true\",\n",
        "        help=\"use zero magnetization constraint\",\n",
        "    )\n",
        "    group.add_argument(\n",
        "        \"--Nf\",\n",
        "        type=int,\n",
        "        default=0,\n",
        "        help=\"number of fermions\",\n",
        "    )\n",
        "\n",
        "    group = parser.add_argument_group(\"network parameters\")\n",
        "    group.add_argument(\n",
        "        \"--net\",\n",
        "        type=str,\n",
        "        default=\"jas\",\n",
        "        choices=[\"jas\", \"rbm\", \"gcnn\", \"rnn_lstm\", \"sym_sinekan\", \"sinekan\", \"mlp\", \"symmlp\"],\n",
        "        help=\"network type\",\n",
        "    )\n",
        "    group.add_argument(\n",
        "        \"--layers\",\n",
        "        type=int,\n",
        "        default=1,\n",
        "        help=\"number of layers\",\n",
        "    )\n",
        "    group.add_argument(\n",
        "        \"--layers_hidden\",\n",
        "          type=parse_tuple,\n",
        "          help=\"Comma-separated tuple for hidden layers, e.g., '64,64'.\"\n",
        "    )\n",
        "    group.add_argument(\n",
        "        \"--grid_size\",\n",
        "        type=int,\n",
        "        default=8,\n",
        "        help=\"grid size of a sinekan model\"\n",
        "    )\n",
        "    group.add_argument(\n",
        "        \"--features\",\n",
        "        type=int,\n",
        "        default=1,\n",
        "        help=\"number of features\",\n",
        "    )\n",
        "    group.add_argument(\n",
        "        \"--dtype\",\n",
        "        type=str,\n",
        "        default=\"float32\",\n",
        "        choices=[\"float32\", \"float64\", \"complex64\", \"complex128\"],\n",
        "        help=\"data type\",\n",
        "    )\n",
        "    group = parser.add_argument_group(\"optimizer parameters\")\n",
        "    group.add_argument(\n",
        "        \"--seed\",\n",
        "        type=int,\n",
        "        default=0,\n",
        "        help=\"random seed, 0 for randomized\",\n",
        "    )\n",
        "    group.add_argument(\n",
        "        \"--optimizer\",\n",
        "        type=str,\n",
        "        default=\"sr\",\n",
        "        choices=[\"adam\", \"sgd\", \"sr\", \"custom\"],\n",
        "        help=\"optimizer type\",\n",
        "    )\n",
        "    group.add_argument(\n",
        "        \"--split_real\",\n",
        "        action=\"store_true\",\n",
        "        help=\"split real and imaginary parts of parameters in the optimizer\",\n",
        "    )\n",
        "    group.add_argument(\n",
        "        \"--batch_size\",\n",
        "        type=int,\n",
        "        default=1024,\n",
        "        help=\"batch size\",\n",
        "    )\n",
        "    group.add_argument(\n",
        "        \"--lr\",\n",
        "        type=float,\n",
        "        default=1e-3,\n",
        "        help=\"learning rate\",\n",
        "    )\n",
        "    group.add_argument(\n",
        "        \"--decay_time\",\n",
        "        type=float,\n",
        "        default=1000,\n",
        "        help=\"controls decay time for learning rate\",\n",
        "    )\n",
        "    group.add_argument(\n",
        "        \"--diag_shift\",\n",
        "        type=float,\n",
        "        default=1e-2,\n",
        "        help=\"diagonal shift of SR\",\n",
        "    )\n",
        "    group.add_argument(\n",
        "        \"--max_step\",\n",
        "        type=int,\n",
        "        default=10**4,\n",
        "        help=\"number of training/sampling steps\",\n",
        "    )\n",
        "    group.add_argument(\n",
        "        \"--drop_step\",\n",
        "        type=int,\n",
        "        default=10**4,\n",
        "        help=\"steps after which to decrease learning rate near converging point\"\n",
        "    )\n",
        "    group.add_argument(\n",
        "        \"--grad_clip\",\n",
        "        type=float,\n",
        "        default=0,\n",
        "        help=\"global norm to clip gradients, 0 for disabled\",\n",
        "    )\n",
        "    group.add_argument(\n",
        "        \"--chunk_size\",\n",
        "        type=int,\n",
        "        default=1024,\n",
        "        help=\"chunk size, 0 for disabled\",\n",
        "    )\n",
        "    group.add_argument(\n",
        "        \"--estim_size\",\n",
        "        type=int,\n",
        "        default=1024**2,\n",
        "        help=\"batch size to estimate the Hamiltonian, 0 for matching 'batch_size'\",\n",
        "    )\n",
        "    group = parser.add_argument_group(\"system parameters\")\n",
        "    group.add_argument(\n",
        "        \"--show_progress\",\n",
        "        action=\"store_true\",\n",
        "        help=\"show progress\",\n",
        "    )\n",
        "    group.add_argument(\n",
        "        \"--cuda\",\n",
        "        type=str,\n",
        "        default=\"auto\",\n",
        "        help=\"GPU ID, empty string for disabling GPU, multi-GPU is not supported yet\",\n",
        "    )\n",
        "    group.add_argument(\n",
        "        \"--run_name\",\n",
        "        type=str,\n",
        "        default=\"\",\n",
        "        help=\"output subdirectory to keep repeated runs, empty string for disabled\",\n",
        "    )\n",
        "    group.add_argument(\n",
        "        \"-o\",\n",
        "        \"--out_dir\",\n",
        "        type=str,\n",
        "        default=\"./out\",\n",
        "        help=\"output directory, empty string for disabled\",\n",
        "    )\n",
        "\n",
        "    return parser\n",
        "\n",
        "def get_ham_net_name(args):\n",
        "    ham_name = \"{ham}_{boundary}\"\n",
        "    if args.sign != \"none\":\n",
        "        ham_name += \"_{sign}\"\n",
        "    ham_name += \"_{ham_dim}d_L{L}\"\n",
        "    if args.L2 and args.L2 != args.L:\n",
        "        ham_name += \",{L2}\"\n",
        "    if args.J2:\n",
        "        ham_name += \"_J2={J2:g}\"\n",
        "    if args.U:\n",
        "        ham_name += \"_U={U:g}\"\n",
        "    if args.V:\n",
        "        ham_name += \"_V={V:g}\"\n",
        "    if args.h:\n",
        "        ham_name += \"_h={h:g}\"\n",
        "    if args.zero_mag:\n",
        "        ham_name += \"_zm\"\n",
        "    if args.Nf:\n",
        "        ham_name += \"_Nf{Nf}\"\n",
        "    ham_name = ham_name.format(**vars(args))\n",
        "\n",
        "    net_name = \"{net}\"\n",
        "    if args.net == \"rbm\":\n",
        "        net_name += \"_a{features}\"\n",
        "    elif args.net != \"jas\":\n",
        "        net_name += \"_l{layers}_f{features}\"\n",
        "\n",
        "    net_name += \"_{optimizer}\"\n",
        "    if args.split_real:\n",
        "        net_name += \"_sp\"\n",
        "    if args.grad_clip:\n",
        "        net_name += \"_gc{grad_clip:g}\"\n",
        "    net_name = net_name.format(**vars(args))\n",
        "\n",
        "    return ham_name, net_name\n",
        "\n",
        "def post_init_args(args):\n",
        "    if args.ham_dim == 1:\n",
        "        assert args.L2 == 0\n",
        "    else:\n",
        "        if args.L2 == 0:\n",
        "            args.L2 = args.L\n",
        "\n",
        "    if args.seed == 0:\n",
        "        # The seed depends on the time and the PID\n",
        "        args.seed = hash((datetime.now(), os.getpid())) & (2**32 - 1)\n",
        "\n",
        "    if args.optimizer == \"sr\" and args.diag_shift == 0:\n",
        "        args.diag_shift = args.lr\n",
        "\n",
        "    if args.chunk_size == 0:\n",
        "        args.chunk_size = None\n",
        "\n",
        "    if args.estim_size == 0:\n",
        "        args.estim_size = args.batch_size\n",
        "\n",
        "    args.ham_name, args.net_name = get_ham_net_name(args)\n",
        "\n",
        "    if args.dtype in [\"float32\", np.float32]:\n",
        "        args.dtype = np.float32\n",
        "    elif args.dtype in [\"float64\", np.float64]:\n",
        "        args.dtype = np.float64\n",
        "    elif args.dtype in [\"complex64\", np.complex64]:\n",
        "        args.dtype = np.complex64\n",
        "    elif args.dtype in [\"complex128\", np.complex128]:\n",
        "        args.dtype = np.complex128\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown dtype: {args.dtype}\")\n",
        "\n",
        "    if args.out_dir:\n",
        "        args.full_out_dir = \"{out_dir}/{ham_name}/{net_name}/\".format(**vars(args))\n",
        "        if args.run_name:\n",
        "            args.full_out_dir = \"{full_out_dir}{run_name}/\".format(**vars(args))\n",
        "        args.log_filename = args.full_out_dir + \"out\"\n",
        "    else:\n",
        "        args.full_out_dir = None\n",
        "        args.log_filename = None\n",
        "\n",
        "def set_env(args):\n",
        "    if args.cuda != \"auto\":\n",
        "        os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.cuda\n",
        "    os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
        "    np.random.seed(args.seed)\n",
        "\n",
        "# --- End Provided Functions --- #\n",
        "\n",
        "# Here is our helper function to build the variational state from the parsed arguments.\n",
        "# (This function uses your already defined get_ham, get_net, and get_sampler functions.)\n",
        "def get_vstate_from_args(args, ham_kwargs=None, net_kwargs=None, sampler_kwargs=None):\n",
        "    \"\"\"\n",
        "    Constructs and returns the variational state (vstate) using the provided arguments.\n",
        "\n",
        "    Parameters:\n",
        "      args : An argparse.Namespace object containing all necessary parameters.\n",
        "      ham_kwargs, net_kwargs, sampler_kwargs : Optional dicts for passing additional keyword\n",
        "                                                arguments to get_ham, get_net, and get_sampler.\n",
        "\n",
        "    Returns:\n",
        "      vstate : The NetKet variational state.\n",
        "      H      : The Hamiltonian (useful for computing expectation values).\n",
        "    \"\"\"\n",
        "    ham_kwargs = ham_kwargs or {}\n",
        "    net_kwargs = net_kwargs or {}\n",
        "    sampler_kwargs = sampler_kwargs or {}\n",
        "\n",
        "    # Build the Hamiltonian, Hilbert space, and lattice graph.\n",
        "    graph, hilbert, H = get_ham(**ham_kwargs)\n",
        "\n",
        "    # Build the neural network model.\n",
        "    model = get_net(graph, hilbert, **net_kwargs)\n",
        "\n",
        "    # Build the sampler.\n",
        "    sampler = get_sampler(graph, hilbert, **sampler_kwargs)\n",
        "\n",
        "    # Construct the variational state.\n",
        "    vstate = nk.vqs.MCState(\n",
        "        sampler,\n",
        "        model,\n",
        "        n_samples=args.batch_size,\n",
        "        n_discard_per_chain=0,\n",
        "        chunk_size=args.chunk_size,\n",
        "        seed=args.seed,\n",
        "    )\n",
        "    return vstate, H, graph, hilbert\n",
        "\n",
        "# ---- In a Jupyter Notebook, simulate command-line arguments ---- #\n",
        "# Here is the command-line argument string you mentioned:\n",
        "#   --ham j1j2_1d --boundary peri --sign mars --J2 0.4 --ham_dim 1 --L 100 --zero_mag\n",
        "#   --net sym_sinekan --layers_hidden 64,64,1 --grid_size 8 --seed 123 --optimizer custom\n",
        "#   --drop_step 50_000 --decay_time 1_000 --max_step 60_000 --show_progress --lr 1e-4\n",
        "\n",
        "# We simulate this by constructing a list of strings:\n",
        "args_list = [\n",
        "    \"--ham\", \"j1j2_1d\",\n",
        "    \"--boundary\", \"peri\",\n",
        "    \"--sign\", \"mars\",\n",
        "    \"--J2\", \"0.4\",\n",
        "    \"--ham_dim\", \"1\",\n",
        "    \"--L\", \"100\",\n",
        "    \"--zero_mag\",\n",
        "    \"--net\", \"symmlp\",\n",
        "    \"--layers_hidden\", \"256,256,1\",\n",
        "    # \"--grid_size\", \"8\",\n",
        "    # \"--net\", \"rbm\",\n",
        "    # \"--features\", \"128\",\n",
        "    \"--seed\", \"123\",\n",
        "    \"--optimizer\", \"custom\",\n",
        "    \"--drop_step\", \"30000\",\n",
        "    \"--decay_time\", \"1000\",\n",
        "    \"--max_step\", \"34000\",\n",
        "    \"--show_progress\",\n",
        "    \"--lr\", \"1e-3\"\n",
        "]\n",
        "\n",
        "# Parse the simulated arguments.\n",
        "parser = get_parser()\n",
        "args = parser.parse_args(args_list)\n",
        "\n",
        "# Post-process the arguments and set environment variables.\n",
        "post_init_args(args)\n",
        "set_env(args)\n",
        "\n",
        "# ---- Build the variational state using our helper function ---- #\n",
        "initial_vstate, H, graph, hilbert = get_vstate_from_args(args)\n",
        "\n",
        "# Now 'vstate' is the variational state built according to your parameters,\n",
        "# and you can proceed to use it (for example, passing it to a VMC driver,\n",
        "# computing expectation values, or loading it later via flax.serialization).\n",
        "\n",
        "print(\"Variational state built with\", initial_vstate.n_parameters, \"parameters.\")\n",
        "print(\"Hamiltonian:\", H)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKrmkpyuCQW7"
      },
      "outputs": [],
      "source": [
        "fp = \"/content/drive/MyDrive/Spin_Lattice/out/j1j2_1d_peri_mars_1d_L100_J2=0.4_zm/symmlp_l1_f1_custom/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMcsBYxM017u"
      },
      "outputs": [],
      "source": [
        "# with open(\"/content/final_vstate (3).mpack\", 'rb') as file:\n",
        "with open(fp + \"final_vstate.mpack\", 'rb') as file:\n",
        "  vstate = flax.serialization.from_bytes(initial_vstate, file.read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpYVW6v7-VQ3",
        "outputId": "822549d8-4cf1-4495-a4d8-e09c3394512f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-37.907705218400494 +/- 0.018664025171303465 , variance: 0.3567061356493305\n"
          ]
        }
      ],
      "source": [
        "# print(vstate.expect(structure_factor).mean.real, \"+/-\", vstate.expect(structure_factor).error_of_mean.real, \", variance:\", vstate.expect(structure_factor).variance.real)\n",
        "print(vstate.expect(H).mean.real, \"+/-\", vstate.expect(H).error_of_mean.real, \", variance:\", vstate.expect(H).variance.real)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
